{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     iD       entity sentiment  \\\n",
      "0  2401  Borderlands  Positive   \n",
      "1  2401  Borderlands  Positive   \n",
      "2  2401  Borderlands  Positive   \n",
      "3  2401  Borderlands  Positive   \n",
      "4  2401  Borderlands  Positive   \n",
      "\n",
      "                                                text  \n",
      "0  im getting on borderlands and i will murder yo...  \n",
      "1  I am coming to the borders and I will kill you...  \n",
      "2  im getting on borderlands and i will kill you ...  \n",
      "3  im coming on borderlands and i will murder you...  \n",
      "4  im getting on borderlands 2 and i will murder ...  \n",
      "         iD  entity sentiment  \\\n",
      "74677  9200  Nvidia  Positive   \n",
      "74678  9200  Nvidia  Positive   \n",
      "74679  9200  Nvidia  Positive   \n",
      "74680  9200  Nvidia  Positive   \n",
      "74681  9200  Nvidia  Positive   \n",
      "\n",
      "                                                    text  \n",
      "74677  Just realized that the Windows partition of my...  \n",
      "74678  Just realized that my Mac window partition is ...  \n",
      "74679  Just realized the windows partition of my Mac ...  \n",
      "74680  Just realized between the windows partition of...  \n",
      "74681  Just like the windows partition of my Mac is l...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "column_names = [\"iD\", \"entity\", \"sentiment\", \"text\"]\n",
    "\n",
    "df = pd.read_csv(\"twitter_training.csv\",names=column_names)\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information of the data set at it's raw state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall information about dataframe is as follows\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74682 entries, 0 to 74681\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   iD         74682 non-null  int64 \n",
      " 1   entity     74682 non-null  object\n",
      " 2   sentiment  74682 non-null  object\n",
      " 3   text       73996 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.3+ MB\n",
      "None\n",
      "The shape of the dataframe is (74682, 4)\n",
      "total number of duplicated rows, 2700\n",
      "Null value distribution \n",
      " iD             0\n",
      "entity         0\n",
      "sentiment      0\n",
      "text         686\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"The overall information about dataframe is as follows\")\n",
    "print(df.info())  # To see the overall information of the data set\n",
    "print(\"The shape of the dataframe is\", df.shape)  # To check the shape of teh dataframe (Nrow,Nccolumns)\n",
    "\n",
    "print(\"total number of duplicated rows,\",df.duplicated().sum()) # Total Number of duplicated values\n",
    "print(\"Null value distribution \\n\",df.isna().sum()) # To know the total number of null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "-As we can we observe from the out put there are about 2700 duplicated rows\n",
    "- And the text column has 686 Null Values\n",
    "- We have to drop/remove them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.dropna()   # Drop rows with any missing values\n",
    "df= df.drop_duplicates()  # Drop duplicate rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall information about dataframe is as follows\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 71656 entries, 0 to 74681\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   iD         71656 non-null  int64 \n",
      " 1   entity     71656 non-null  object\n",
      " 2   sentiment  71656 non-null  object\n",
      " 3   text       71656 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.7+ MB\n",
      "None\n",
      "The shape of the dataframe is (71656, 4)\n",
      "total number of duplicated rows, 0\n",
      "Null value distribution \n",
      " iD           0\n",
      "entity       0\n",
      "sentiment    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"The overall information about dataframe is as follows\")\n",
    "print(df.info())  # To see the overall information of the data set\n",
    "print(\"The shape of the dataframe is\", df.shape)  # To check the shape of teh dataframe (Nrow,Nccolumns)\n",
    "\n",
    "print(\"total number of duplicated rows,\",df.duplicated().sum()) # Total Number of duplicated values\n",
    "print(\"Null value distribution \\n\",df.isna().sum()) # To know the total number of null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stopwords\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(df_path):\n",
    "    \n",
    "    column_names = [\"iD\", \"entity\", \"sentiment\", \"text\"]\n",
    "    df = pd.read_csv(df_path,names=column_names)\n",
    "\n",
    "    df = pd.read_csv(\"twitter_training.csv\",names=column_names) # Reading csv file\n",
    "    df= df.dropna()   # Drop rows with any missing values\n",
    "    df= df.drop_duplicates()  # Drop duplicate rows\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df['text'] = df['text'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in stop_words]))\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iD</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting borderlands murder ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I coming borders I kill all,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting borderlands kill all,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming borderlands murder all,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting borderlands 2 murder all,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     iD       entity sentiment                                  text\n",
       "0  2401  Borderlands  Positive       im getting borderlands murder ,\n",
       "1  2401  Borderlands  Positive          I coming borders I kill all,\n",
       "2  2401  Borderlands  Positive      im getting borderlands kill all,\n",
       "3  2401  Borderlands  Positive     im coming borderlands murder all,\n",
       "4  2401  Borderlands  Positive  im getting borderlands 2 murder all,"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = wrangle(\"twitter_training.csv\")\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
